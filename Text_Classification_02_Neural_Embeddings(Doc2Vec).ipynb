{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Classification_02_Neural_Embeddings(Doc2Vec)",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QB1PbloEK2_",
        "outputId": "f73ec851-c389-4737-99c7-68acd724f2dd"
      },
      "source": [
        "import pandas as pd \r\n",
        "import numpy as np \r\n",
        "import nltk \r\n",
        "from nltk.tokenize import TweetTokenizer\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument \r\n",
        "nltk.download('stopwords')\r\n",
        "\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')\r\n",
        "\r\n",
        "import regex as re \r\n",
        "from gensim.parsing.preprocessing import remove_stopwords"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLsytO9yFCEN"
      },
      "source": [
        "\"In a variation on the popular task of sentiment analysis, this dataset contains labels for the emotional content (such as happiness, sadness, and anger) of texts. Hundreds to thousands of examples across 13 labels. A subset of this data is used in an experiment we uploaded to Microsoft’s Cortana Intelligence Gallery.\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPtYTq7uFCfb",
        "outputId": "e192f786-458c-4e65-aa20-8a67fbacccfe"
      },
      "source": [
        "#downloding data\r\n",
        "!wget -P DATAPATH https://raw.githubusercontent.com/practical-nlp/practical-nlp/master/Ch4/Data/Sentiment%20and%20Emotion%20in%20Text/train_data.csv\r\n",
        "!wget -P DATAPATH https://raw.githubusercontent.com/practical-nlp/practical-nlp/master/Ch4/Data/Sentiment%20and%20Emotion%20in%20Text/test_data.csv\r\n",
        "!ls -lah DATAPATH"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-28 15:15:23--  https://raw.githubusercontent.com/practical-nlp/practical-nlp/master/Ch4/Data/Sentiment%20and%20Emotion%20in%20Text/train_data.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2479133 (2.4M) [text/plain]\n",
            "Saving to: ‘DATAPATH/train_data.csv’\n",
            "\n",
            "train_data.csv      100%[===================>]   2.36M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2021-01-28 15:15:23 (30.3 MB/s) - ‘DATAPATH/train_data.csv’ saved [2479133/2479133]\n",
            "\n",
            "--2021-01-28 15:15:23--  https://raw.githubusercontent.com/practical-nlp/practical-nlp/master/Ch4/Data/Sentiment%20and%20Emotion%20in%20Text/test_data.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 783640 (765K) [text/plain]\n",
            "Saving to: ‘DATAPATH/test_data.csv’\n",
            "\n",
            "test_data.csv       100%[===================>] 765.27K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2021-01-28 15:15:24 (19.3 MB/s) - ‘DATAPATH/test_data.csv’ saved [783640/783640]\n",
            "\n",
            "total 3.2M\n",
            "drwxr-xr-x 2 root root 4.0K Jan 28 15:15 .\n",
            "drwxr-xr-x 1 root root 4.0K Jan 28 15:15 ..\n",
            "-rw-r--r-- 1 root root 766K Jan 28 15:15 test_data.csv\n",
            "-rw-r--r-- 1 root root 2.4M Jan 28 15:15 train_data.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "v-JsuO6dFN2H",
        "outputId": "b74ae6f6-a7d7-4335-8b06-b85e9709a3e6"
      },
      "source": [
        "train_df = pd.read_csv('/content/DATAPATH/train_data.csv')\r\n",
        "train_df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>empty</td>\n",
              "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sadness</td>\n",
              "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sadness</td>\n",
              "      <td>Funeral ceremony...gloomy friday...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>enthusiasm</td>\n",
              "      <td>wants to hang out with friends SOON!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@dannycastillo We want to trade with someone w...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    sentiment                                            content\n",
              "0       empty  @tiffanylue i know  i was listenin to bad habi...\n",
              "1     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
              "2     sadness                Funeral ceremony...gloomy friday...\n",
              "3  enthusiasm               wants to hang out with friends SOON!\n",
              "4     neutral  @dannycastillo We want to trade with someone w..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQA32oiYGBqn",
        "outputId": "c2a52a45-b556-4580-ae27-436b409bcef5"
      },
      "source": [
        "train_df['sentiment'].value_counts()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "worry         7433\n",
              "neutral       6340\n",
              "sadness       4828\n",
              "happiness     2986\n",
              "love          2068\n",
              "surprise      1613\n",
              "hate          1187\n",
              "fun           1088\n",
              "relief        1021\n",
              "empty          659\n",
              "enthusiasm     522\n",
              "boredom        157\n",
              "anger           98\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "PQZSU8CdFZbw",
        "outputId": "0d8abf02-5637-4d97-ef67-08ad49b4d902"
      },
      "source": [
        "#Lets take the first 3 categories and leave out the rest \r\n",
        "top_3 = ['neutral','happiness','worry']\r\n",
        "df_subset = train_df[train_df['sentiment'].isin(top_3)]\r\n",
        "df_subset.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@dannycastillo We want to trade with someone w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>worry</td>\n",
              "      <td>Re-pinging @ghostridah14: why didn't you go to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>worry</td>\n",
              "      <td>Hmmm. http://www.djhero.com/ is down</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>neutral</td>\n",
              "      <td>cant fall asleep</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>worry</td>\n",
              "      <td>Choked on her retainers</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment                                            content\n",
              "4    neutral  @dannycastillo We want to trade with someone w...\n",
              "5      worry  Re-pinging @ghostridah14: why didn't you go to...\n",
              "7      worry               Hmmm. http://www.djhero.com/ is down\n",
              "10   neutral                                   cant fall asleep\n",
              "11     worry                            Choked on her retainers"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxjG8lzIVbiI",
        "outputId": "949637df-f162-4fe4-aca2-d916fa6e9b2c"
      },
      "source": [
        "df_subset['sentiment'].value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "worry        7433\n",
              "neutral      6340\n",
              "happiness    2986\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djNCzZgxGZOK"
      },
      "source": [
        "## Text pre-processing:\r\n",
        "\r\n",
        "Tweets are different. Somethings to consider:\r\n",
        "\r\n",
        "Removing @mentions, and urls perhaps?\r\n",
        "using NLTK Tweet tokenizer instead of a regular one\r\n",
        "stopwords, numbers as usual."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keR9wRv0Gu4S"
      },
      "source": [
        "#strip_handles removes personal information such as twitter handles, which don't\r\n",
        "#contribute to emotion in the tweet. preserve_case=False converts everything to lowercase.\r\n",
        "tweeter = TweetTokenizer(strip_handles=True, preserve_case=False)\r\n",
        "mystopwords = set(stopwords.words('english'))\r\n",
        "\r\n",
        "#Function to tokenize tweets, remove stopwords and numbers. \r\n",
        "#Keeping punctuations and emoticon symbols could be relevant for this task!\r\n",
        "def preprocess_corpus(texts):\r\n",
        "  def remove_stop_digits(tokens):\r\n",
        "    return [token for token in tokens if token not in mystopwords and not token.isdigit()]\r\n",
        "    #This return statement below uses the above function to process twitter tokenizer output further. \r\n",
        "  return [remove_stop_digits(tweeter.tokenize(content)) for content in texts]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09UEZjqsSiN5",
        "outputId": "b7c8d1f5-5206-4b48-c70c-0e1863af2592"
      },
      "source": [
        "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \r\n",
        " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \r\n",
        " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \r\n",
        " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \r\n",
        " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√']\r\n",
        "\r\n",
        "def clean_text(text):\r\n",
        "  text = str(text)\r\n",
        "  for punc in puncts:\r\n",
        "      if punc in text:\r\n",
        "          text = text.replace(punc, ' ')\r\n",
        "  return text\r\n",
        "\r\n",
        "def remove_emoji(text):\r\n",
        "    emoji_pattern = re.compile(\"[\"\r\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\r\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\r\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\r\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\r\n",
        "                           u\"\\U00002702-\\U000027B0\"\r\n",
        "                           u\"\\U000024C2-\\U0001F251\"\r\n",
        "                           \"]+\", flags=re.UNICODE)\r\n",
        "    return emoji_pattern.sub(r'', text)\r\n",
        "    \r\n",
        "df_subset['content'] = df_subset['content'].apply(lambda x: remove_emoji(x)) \r\n",
        "df_subset['content'] = df_subset['content'].apply(lambda x: clean_text(x)) \r\n",
        "df_subset['content'] = df_subset['content'].apply(lambda x: re.sub(r'http\\S+','',x))\r\n",
        "df_subset['content'] = df_subset['content'].apply(lambda x: re.sub(\"@[\\w]*\", '', x))\r\n",
        "df_subset['content'] = df_subset['content'].apply(lambda x:' '.join(x.split()))\r\n",
        "df_subset['content'] = df_subset['content'].apply(lambda x: remove_stopwords(x))\r\n",
        "\r\n",
        "#df_subset contains only the three categories we choose\r\n",
        "mydata = preprocess_corpus(df_subset['content'])\r\n",
        "mycats = df_subset['sentiment']\r\n",
        "print(len(mydata), len(mycats))\r\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16759 16759\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3nFUEWPJ8kZ"
      },
      "source": [
        "#Splitting data into train and test\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(mydata, mycats, random_state=2018)\r\n",
        "\r\n",
        "#Preparing training data in Doc2Vec format:\r\n",
        "train_doc2vec =  [TaggedDocument((d), tags=[str(i)]) for i, d in enumerate(X_train)]\r\n",
        "#Train a doc2vec model to learn tweet representations. Use only training data!!\r\n",
        "model = Doc2Vec(vector_size=50, alpha=0.025, min_count=5, dim=1, epochs=100)\r\n",
        "model.build_vocab(train_doc2vec)\r\n",
        "model.train(train_doc2vec, total_examples=model.corpus_count, epochs=model.epochs)\r\n",
        "model.save('d2v.model')  "
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2S8EK2ECPWs-",
        "outputId": "ff816de7-6825-4a3d-ffa5-cef51cba06cc"
      },
      "source": [
        "#Infer the feature representation for training and test data using the trained model\r\n",
        "model = Doc2Vec.load('d2v.model')\r\n",
        "#infer in multiple steps to get a stable representation\r\n",
        "train_vectors = [model.infer_vector(list_of_tokens, steps=50)for list_of_tokens in X_train]\r\n",
        "test_vectors =  [model.infer_vector(list_of_tokens, steps=50)for list_of_tokens in X_test]\r\n",
        "\r\n",
        "#Use any classifier to train the model\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "\r\n",
        "myclass = LogisticRegression(class_weight='balanced')\r\n",
        "myclass.fit(train_vectors, y_train)\r\n",
        "preds = myclass.predict(test_vectors)\r\n",
        "\r\n",
        "from sklearn import metrics\r\n",
        "print(metrics.classification_report(y_test, preds))\r\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   happiness       0.34      0.54      0.42       799\n",
            "     neutral       0.48      0.43      0.45      1551\n",
            "       worry       0.58      0.49      0.53      1840\n",
            "\n",
            "    accuracy                           0.48      4190\n",
            "   macro avg       0.47      0.49      0.47      4190\n",
            "weighted avg       0.50      0.48      0.48      4190\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5K0Z3Gq3VCZA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6H4UbFJcWq-G"
      },
      "source": [
        "Now the performance of this models seems rather poor.  There could be couple of interertations for this poor results.\r\n",
        "\r\n",
        "**1.** Unlike full news articles or even well-formed sentences, tweets contain very little data pper instance.\r\n",
        "\r\n",
        "**2.** Further people write with a wide variety in spelling and syntax when they tweet. There are a lot of emoticons in different forms which our feature representation failed to capture.\r\n",
        "\r\n"
      ]
    }
  ]
}